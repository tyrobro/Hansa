{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "config-header",
   "metadata": {},
   "source": [
    "# Hansa\n",
    "## Configuration and Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "config-cell",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n",
    "import logging\n",
    "logging.getLogger('tensorflow').setLevel(logging.ERROR)\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix, classification_report, roc_curve, auc\n",
    "import seaborn as sns\n",
    "import time\n",
    "from datetime import datetime\n",
    "\n",
    "SEED = 69\n",
    "np.random.seed(SEED)\n",
    "tf.random.set_seed(SEED)\n",
    "\n",
    "DATA_DIR = os.path.join('..', 'data', 'train')\n",
    "TEST_DIR = os.path.join('..', 'data', 'test')\n",
    "IMG_SIZE = (32, 32)\n",
    "BATCH_SIZE = 32\n",
    "VALIDATION_SPLIT = 0.2\n",
    "\n",
    "LEARNING_RATE = 0.00001\n",
    "EPOCHS = 20\n",
    "DROPOUT_RATE = 0.5\n",
    "L2_REGULARIZATION = 0.001\n",
    "\n",
    "EARLY_STOPPING_PATIENCE = 3\n",
    "REDUCE_LR_PATIENCE = 2\n",
    "REDUCE_LR_FACTOR = 0.5\n",
    "\n",
    "MODEL_NAME = 'hansa_best.keras'\n",
    "HISTORY_PLOT = 'training_history.png'\n",
    "CONFUSION_MATRIX_PLOT = 'confusion_matrix.png'\n",
    "\n",
    "print(f\"Configuration loaded at {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\")\n",
    "print(f\"TensorFlow version: {tf.__version__}\")\n",
    "print(f\"GPU Available: {tf.config.list_physical_devices('GPU')}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "data-loading-header",
   "metadata": {},
   "source": [
    "## Data Loading and Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "data-loading",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Loading Training Data...\")\n",
    "train_ds = tf.keras.utils.image_dataset_from_directory(\n",
    "    DATA_DIR,\n",
    "    validation_split=VALIDATION_SPLIT,\n",
    "    subset=\"training\",\n",
    "    seed=SEED,\n",
    "    image_size=IMG_SIZE,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    label_mode='binary'\n",
    ")\n",
    "\n",
    "print(\"\\nLoading Validation Data...\")\n",
    "val_ds = tf.keras.utils.image_dataset_from_directory(\n",
    "    DATA_DIR,\n",
    "    validation_split=VALIDATION_SPLIT,\n",
    "    subset=\"validation\",\n",
    "    seed=SEED,\n",
    "    image_size=IMG_SIZE,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    label_mode='binary'\n",
    ")\n",
    "\n",
    "print(\"\\nLoading Test Data...\")\n",
    "test_ds = tf.keras.utils.image_dataset_from_directory(\n",
    "    TEST_DIR,\n",
    "    image_size=IMG_SIZE,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    label_mode='binary',\n",
    "    shuffle=False \n",
    ")\n",
    "\n",
    "class_names = train_ds.class_names\n",
    "print(f\"\\nClasses: {class_names}\")\n",
    "\n",
    "AUTOTUNE = tf.data.AUTOTUNE\n",
    "train_ds = train_ds.cache().shuffle(1000).prefetch(buffer_size=AUTOTUNE)\n",
    "val_ds = val_ds.cache().prefetch(buffer_size=AUTOTUNE)\n",
    "test_ds = test_ds.cache().prefetch(buffer_size=AUTOTUNE)\n",
    "\n",
    "print(\"\\nData pipeline optimized for efficient training.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "model-header",
   "metadata": {},
   "source": [
    "## Model Architecture\n",
    "### CNN with Batch Normalization, Dropout, and L2 Regularization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "model-definition",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import layers, models, regularizers\n",
    "\n",
    "data_augmentation = tf.keras.Sequential([\n",
    "    layers.RandomFlip(\"horizontal\"),\n",
    "    layers.RandomRotation(0.1),\n",
    "    layers.RandomZoom(0.1),\n",
    "])\n",
    "\n",
    "model = models.Sequential([\n",
    "    layers.Input(shape=(32, 32, 3)),\n",
    "    \n",
    "    data_augmentation,\n",
    "    \n",
    "    layers.Rescaling(1./255),\n",
    "\n",
    "    layers.Conv2D(32, (3, 3), padding='same', activation='relu'),\n",
    "    layers.BatchNormalization(),\n",
    "    layers.Conv2D(32, (3, 3), padding='same', activation='relu'),\n",
    "    layers.BatchNormalization(),\n",
    "    layers.MaxPooling2D((2, 2)),\n",
    "    layers.Dropout(0.2),\n",
    "\n",
    "    layers.Conv2D(64, (3, 3), padding='same', activation='relu'),\n",
    "    layers.BatchNormalization(),\n",
    "    layers.Conv2D(64, (3, 3), padding='same', activation='relu'),\n",
    "    layers.BatchNormalization(),\n",
    "    layers.MaxPooling2D((2, 2)),\n",
    "    layers.Dropout(0.3),\n",
    "\n",
    "    layers.Conv2D(128, (3, 3), padding='same', activation='relu'),\n",
    "    layers.BatchNormalization(),\n",
    "    layers.MaxPooling2D((2, 2)),\n",
    "    layers.Dropout(0.3),\n",
    "    \n",
    "    layers.GlobalAveragePooling2D(),\n",
    "\n",
    "    layers.Dense(128, activation='relu', \n",
    "                 kernel_regularizer=regularizers.l2(L2_REGULARIZATION)),\n",
    "    layers.Dropout(DROPOUT_RATE),\n",
    "    layers.Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"MODEL ARCHITECTURE\")\n",
    "print(\"=\"*50)\n",
    "model.summary()\n",
    "print(\"=\"*50)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "compile-header",
   "metadata": {},
   "source": [
    "## Model Compilation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "model-compile",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = tf.keras.optimizers.legacy.Adam(learning_rate=LEARNING_RATE)\n",
    "\n",
    "model.compile(\n",
    "    optimizer=optimizer,\n",
    "    loss='binary_crossentropy',\n",
    "    metrics=['accuracy', \n",
    "             tf.keras.metrics.Precision(name='precision'),\n",
    "             tf.keras.metrics.Recall(name='recall')]\n",
    ")\n",
    "\n",
    "print(\"Model compiled successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "callbacks-header",
   "metadata": {},
   "source": [
    "## Training Callbacks Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "callbacks",
   "metadata": {},
   "outputs": [],
   "source": [
    "early_stopping = tf.keras.callbacks.EarlyStopping(\n",
    "    monitor='val_loss',\n",
    "    patience=EARLY_STOPPING_PATIENCE,\n",
    "    restore_best_weights=True,\n",
    "    verbose=2\n",
    ")\n",
    "\n",
    "checkpoint = tf.keras.callbacks.ModelCheckpoint(\n",
    "    MODEL_NAME,\n",
    "    monitor='val_accuracy',\n",
    "    save_best_only=True,\n",
    "    mode='max',\n",
    "    verbose=2\n",
    ")\n",
    "\n",
    "reduce_lr = tf.keras.callbacks.ReduceLROnPlateau(\n",
    "    monitor='val_loss',\n",
    "    factor=REDUCE_LR_FACTOR,\n",
    "    patience=REDUCE_LR_PATIENCE,\n",
    "    min_lr=1e-7,\n",
    "    verbose=2\n",
    ")\n",
    "\n",
    "callbacks = [early_stopping, checkpoint, reduce_lr]\n",
    "print(\"Callbacks configured:\")\n",
    "print(\"- Early Stopping\")\n",
    "print(\"- Model Checkpoint\")\n",
    "print(\"- Learning Rate Reduction\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "training-header",
   "metadata": {},
   "source": [
    "## Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "training",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"STARTING TRAINING\")\n",
    "print(\"=\"*50)\n",
    "print(f\"Start Time: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\")\n",
    "print(f\"Epochs: {EPOCHS}\")\n",
    "print(f\"Batch Size: {BATCH_SIZE}\")\n",
    "print(f\"Learning Rate: {LEARNING_RATE}\")\n",
    "print(\"=\"*50 + \"\\n\")\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "history = model.fit(\n",
    "    train_ds,\n",
    "    validation_data=val_ds,\n",
    "    epochs=EPOCHS,\n",
    "    callbacks=callbacks,\n",
    "    verbose=2\n",
    ")\n",
    "\n",
    "training_time = time.time() - start_time\n",
    "\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"TRAINING COMPLETED\")\n",
    "print(\"=\"*50)\n",
    "print(f\"Total Training Time: {training_time/60:.2f} minutes\")\n",
    "print(f\"Average Time per Epoch: {training_time/len(history.history['loss']):.2f} seconds\")\n",
    "print(\"=\"*50)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "visualization-header",
   "metadata": {},
   "source": [
    "## Training History Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "visualization",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_training_history(history):\n",
    "    \n",
    "    fig, axes = plt.subplots(2, 2, figsize=(15, 10))\n",
    "    \n",
    "    epochs_range = range(len(history.history['accuracy']))\n",
    "    \n",
    "    axes[0, 0].plot(epochs_range, history.history['accuracy'], label='Training')\n",
    "    axes[0, 0].plot(epochs_range, history.history['val_accuracy'], label='Validation')\n",
    "    axes[0, 0].set_title('Accuracy', fontsize=14, fontweight='bold')\n",
    "    axes[0, 0].set_xlabel('Epoch')\n",
    "    axes[0, 0].set_ylabel('Accuracy')\n",
    "    axes[0, 0].legend()\n",
    "    axes[0, 0].grid(True, alpha=0.3)\n",
    "    \n",
    "    axes[0, 1].plot(epochs_range, history.history['loss'], label='Training')\n",
    "    axes[0, 1].plot(epochs_range, history.history['val_loss'], label='Validation')\n",
    "    axes[0, 1].set_title('Loss', fontsize=14, fontweight='bold')\n",
    "    axes[0, 1].set_xlabel('Epoch')\n",
    "    axes[0, 1].set_ylabel('Loss')\n",
    "    axes[0, 1].legend()\n",
    "    axes[0, 1].grid(True, alpha=0.3)\n",
    "    \n",
    "    axes[1, 0].plot(epochs_range, history.history['precision'], label='Training')\n",
    "    axes[1, 0].plot(epochs_range, history.history['val_precision'], label='Validation')\n",
    "    axes[1, 0].set_title('Precision', fontsize=14, fontweight='bold')\n",
    "    axes[1, 0].set_xlabel('Epoch')\n",
    "    axes[1, 0].set_ylabel('Precision')\n",
    "    axes[1, 0].legend()\n",
    "    axes[1, 0].grid(True, alpha=0.3)\n",
    "    \n",
    "    axes[1, 1].plot(epochs_range, history.history['recall'], label='Training')\n",
    "    axes[1, 1].plot(epochs_range, history.history['val_recall'], label='Validation')\n",
    "    axes[1, 1].set_title('Recall', fontsize=14, fontweight='bold')\n",
    "    axes[1, 1].set_xlabel('Epoch')\n",
    "    axes[1, 1].set_ylabel('Recall')\n",
    "    axes[1, 1].legend()\n",
    "    axes[1, 1].grid(True, alpha=0.3)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig(HISTORY_PLOT, dpi=300, bbox_inches='tight')\n",
    "    plt.show()\n",
    "    \n",
    "    print(f\"\\nTraining history plot saved as '{HISTORY_PLOT}'\")\n",
    "\n",
    "plot_training_history(history)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "evaluation-header",
   "metadata": {},
   "source": [
    "## Model Evaluation on Test Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "evaluation",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"EVALUATING ON TEST DATA\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "test_loss, test_acc, test_precision, test_recall = model.evaluate(test_ds, verbose=1)\n",
    "test_f1 = 2 * (test_precision * test_recall) / (test_precision + test_recall)\n",
    "\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"TEST SET RESULTS\")\n",
    "print(\"=\"*50)\n",
    "print(f\"Loss:      {test_loss:.4f}\")\n",
    "print(f\"Accuracy:  {test_acc*100:.2f}%\")\n",
    "print(f\"Precision: {test_precision*100:.2f}%\")\n",
    "print(f\"Recall:    {test_recall*100:.2f}%\")\n",
    "print(f\"F1-Score:  {test_f1*100:.2f}%\")\n",
    "print(\"=\"*50)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "confusion-header",
   "metadata": {},
   "source": [
    "## Confusion Matrix and ROC Curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "confusion-matrix",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_probs = model.predict(test_ds)\n",
    "y_pred = (y_pred_probs > 0.5).astype(int).flatten()\n",
    "\n",
    "y_true = np.concatenate([y for x, y in test_ds], axis=0)\n",
    "\n",
    "cm = confusion_matrix(y_true, y_pred)\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(15, 5))\n",
    "\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', ax=axes[0],\n",
    "            xticklabels=class_names, yticklabels=class_names)\n",
    "axes[0].set_title('Confusion Matrix', fontsize=14, fontweight='bold')\n",
    "axes[0].set_ylabel('True Label')\n",
    "axes[0].set_xlabel('Predicted Label')\n",
    "\n",
    "fpr, tpr, thresholds = roc_curve(y_true, y_pred_probs)\n",
    "roc_auc = auc(fpr, tpr)\n",
    "\n",
    "axes[1].plot(fpr, tpr, color='darkorange', lw=2, \n",
    "             label=f'ROC curve (AUC = {roc_auc:.2f})')\n",
    "axes[1].plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--', label='Random')\n",
    "axes[1].set_xlim([0.0, 1.0])\n",
    "axes[1].set_ylim([0.0, 1.05])\n",
    "axes[1].set_xlabel('False Positive Rate')\n",
    "axes[1].set_ylabel('True Positive Rate')\n",
    "axes[1].set_title('ROC Curve', fontsize=14, fontweight='bold')\n",
    "axes[1].legend(loc=\"lower right\")\n",
    "axes[1].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(CONFUSION_MATRIX_PLOT, dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(f\"\\nConfusion matrix and ROC curve saved as '{CONFUSION_MATRIX_PLOT}'\")\n",
    "print(f\"AUC Score: {roc_auc:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "classification-report-header",
   "metadata": {},
   "source": [
    "## Detailed Classification Report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "classification-report",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"CLASSIFICATION REPORT\")\n",
    "print(\"=\"*50)\n",
    "print(classification_report(y_true, y_pred, target_names=class_names))\n",
    "print(\"=\"*50)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sample-predictions-header",
   "metadata": {},
   "source": [
    "## Sample Predictions Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sample-predictions",
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_sample_predictions(dataset, model, num_samples=9):\n",
    "\n",
    "    plt.figure(figsize=(15, 15))\n",
    "    \n",
    "    images, labels = next(iter(dataset))\n",
    "    predictions = model.predict(images[:num_samples])\n",
    "    \n",
    "    for i in range(num_samples):\n",
    "        plt.subplot(3, 3, i + 1)\n",
    "        plt.imshow(images[i].numpy().astype(\"uint8\"))\n",
    "        \n",
    "        pred_class = 1 if predictions[i] > 0.5 else 0\n",
    "        true_class = int(labels[i])\n",
    "        confidence = predictions[i][0] if pred_class == 1 else 1 - predictions[i][0]\n",
    "        \n",
    "        color = 'green' if pred_class == true_class else 'red'\n",
    "        \n",
    "        plt.title(f\"True: {class_names[true_class]}\\n\"\n",
    "                 f\"Pred: {class_names[pred_class]} ({confidence*100:.1f}%)\",\n",
    "                 color=color, fontweight='bold')\n",
    "        plt.axis('off')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig('sample_predictions.png', dpi=300, bbox_inches='tight')\n",
    "    plt.show()\n",
    "    print(\"Sample predictions saved as 'sample_predictions.png'\")\n",
    "\n",
    "show_sample_predictions(test_ds, model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "save-model-header",
   "metadata": {},
   "source": [
    "## Save Final Model and Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "save-model",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "model.save('hansa.keras')\n",
    "print(f\"Final model saved as 'hansa.keras'\")\n",
    "\n",
    "config = {\n",
    "    'img_size': IMG_SIZE,\n",
    "    'batch_size': BATCH_SIZE,\n",
    "    'learning_rate': LEARNING_RATE,\n",
    "    'epochs_trained': len(history.history['loss']),\n",
    "    'final_train_accuracy': float(history.history['accuracy'][-1]),\n",
    "    'final_val_accuracy': float(history.history['val_accuracy'][-1]),\n",
    "    'test_accuracy': float(test_acc),\n",
    "    'test_precision': float(test_precision),\n",
    "    'test_recall': float(test_recall),\n",
    "    'test_f1': float(test_f1),\n",
    "    'auc_score': float(roc_auc),\n",
    "    'class_names': class_names,\n",
    "    'training_time_minutes': training_time/60,\n",
    "    'timestamp': datetime.now().strftime('%Y-%m-%d %H:%M:%S')\n",
    "}\n",
    "\n",
    "with open('training_config.json', 'w') as f:\n",
    "    json.dump(config, f, indent=4)\n",
    "\n",
    "print(\"Training configuration saved as 'training_config.json'\")\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"ALL DONE! ðŸŽ‰\")\n",
    "print(\"=\"*50)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (Hansa)",
   "language": "python",
   "name": "hansa_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
